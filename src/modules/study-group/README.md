An AI Agent simulation framework, inspired by Google's Concordia framework.

Components:
  - Actors represent an identity/personality in the simulation
  - Environments represent facets of the universe which are observable and measurable.
  - GameMasters translate an Actors intentions into realistic outcomes.
    - GameMasters filter objective observations from the Environment into the perceived observations of the agent.
    - GameMasters decide which actor should take a turn next



    - Actors do not directly act on the world, they declare their intentions and 
    - Actors have a set of composable ContextComponent's which generate the text used in the actors LLM prompts.
    - Actors have a single ActionComponent which uses the output of the ContextComponents to decide what the actors next intended action should be.
    - Actors update their ContextComponents through a `receiveObservations` method.
    the 


The simulation loop

```
// pseudocode
scene = nextScene();
while (!scene.isFinished()) {
  environments.update(scene);
  actors = scene.getActors();
  for (actor of actors) {
    // game master generates observations for the actor
    // actor chooses action
    // game master resolves the action
    // environments record the results
  }
}
// game master summarizes the scene
// environments update with the summary
// actors receive partial observations based on the summary
```

1. [Setup] Each agent receives observations about the premise of the simulation
2. [Scene start] GM chooses which actors are in the scene
3. GM generates an observation for the relevant actors, based on their perceptions/senses
4. [Actor Loop] The actor generates a proposed action
5. The GM grounds the intended action to a resolved result.
6. Environments receives updates
7. [loop]


## Design decisions
Should 'partial' observations happen at the beginning of a 'turn' to set it up, or at the end, to record the final results?
 --> Do at the beginning of the actor loop, so that it only needs to be done once per loop, instead of once for each actors resolved action.
 --> The downside is that across scene boundaries, an agent may not have relevant observations from actors who took a turn after it. 
 at the end of the scene, we need to give every actor one more chance to receive observations (without actions)



## Prompts
**1. Agent Action**
  -> [static] Name, persona, environment
  -> [semi-dynamic] memories (aka, past observations and logged actions)
  -> [dynamic] current_observations -> generated by GameMaster, filtered and interpeted to match the agents perception

**2. GameMaster Partial Observation**
Generates new observations that the Agent/Actor will receive, based on their perceptions

**3. GameMaster Resolve Action**
Combines the actors intentions with the 'reality' of the other environments and other actors goals/intentions, to determine an actual final result.
